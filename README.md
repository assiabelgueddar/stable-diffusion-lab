# Stable Diffusion Lab â€” Fine-Tuning avec Dataset PersonnalisÃ© 

Ce projet vous guide Ã  travers les Ã©tapes nÃ©cessaires pour **entraÃ®ner un modÃ¨le Stable Diffusion** avec vos propres images et lÃ©gendes Ã  lâ€™aide de Hugging Face `diffusers`.

##  PrÃ©requis

* Python 3.9+
* GPU avec CUDA (recommandÃ©)
* Environnement Google Colab ou local configurÃ©
* `git`, `wget` installÃ©s

---

##  Ã‰tapes d'exÃ©cution

### 1. Cloner le dÃ©pÃ´t Git

```bash
!git clone https://github.com/assiabelgueddar/stable-diffusion-lab.git
%cd stable-diffusion-lab
```

### 2. Installer les dÃ©pendances

```bash
!pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install git+https://github.com/huggingface/diffusers
!pip install transformers accelerate datasets pandas
```

### 3. PrÃ©parer le dataset

Assurez-vous que le fichier `train_data.csv` contient deux colonnes :

* `image` : chemin vers lâ€™image
* `text` : lÃ©gende de lâ€™image

Ensuite :

```bash
!python prepare_dataset.py
```

### 4. Configurer `accelerate`

```bash
!accelerate config default
```

> Cela crÃ©e automatiquement un fichier `default_config.yaml` pour la configuration de l'entraÃ®nement (ex. sur une seule machine, un seul GPU).

### 5. TÃ©lÃ©charger le script d'entraÃ®nement

```bash
!wget https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image.py
```

### 6. Transformer les donnÃ©es en format Hugging Face

```python
from datasets import Dataset, DatasetDict, Image
import pandas as pd

# Charger les donnÃ©es
df = pd.read_csv("train_data.csv")
df = df.rename(columns={"text": "caption"})
ds = Dataset.from_pandas(df)
ds = ds.cast_column("image", Image())
ds_dict = DatasetDict({"train": ds})
ds_dict.save_to_disk("hf_dataset")
```

### 7. (Optionnel) Recharger et vÃ©rifier le dataset

```python
from datasets import load_from_disk
ds = load_from_disk("hf_dataset")
print(ds["train"][0])
```

### 8. Lancer l'entraÃ®nement

```bash
!accelerate launch train_text_to_image.py \
  --pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4 \
  --train_data_dir=hf_dataset \
  --image_column=image \
  --caption_column=caption \
  --output_dir=output \
  --resolution=512 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate=5e-6 \
  --lr_scheduler=constant \
  --lr_warmup_steps=0 \
  --max_train_steps=1000 \
  --checkpointing_steps=500 \
  --validation_prompt="a fluffy white cat with green eyes" \
  --seed=42
```

---

## ğŸ“ Structure recommandÃ©e

```
stable-diffusion-lab/
â”œâ”€â”€ train_data.csv
â”œâ”€â”€ prepare_dataset.py
â”œâ”€â”€ train_text_to_image.py
â”œâ”€â”€ hf_dataset/
â”œâ”€â”€ output/
â””â”€â”€ README.md
```

---

##  Remarques

* Le modÃ¨le prÃ©-entraÃ®nÃ© utilisÃ© est `CompVis/stable-diffusion-v1-4`.
* Le `caption_column` et `image_column` doivent correspondre aux noms de colonnes dans `train_data.csv`.
* L'ajustement fin utilise 1000 Ã©tapes avec un batch size de 1.

---

##  Contact

Ce projet a Ã©tÃ© initialement prÃ©parÃ© par **Assia Belgueddar**.
Pour toute question ou collaboration : [GitHub Profile](https://github.com/assiabelgueddar)

---

Souhaites-tu que je te gÃ©nÃ¨re ce fichier en `.md` prÃªt Ã  Ãªtre ajoutÃ© dans ton dÃ©pÃ´t GitHub ?
